{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "166accc8",
      "metadata": {},
      "source": [
        "# Postgres Methods & Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "db49ae82",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import psycopg2\n",
        "import json\n",
        "# import redis\n",
        "\n",
        "# from qdrant_client import QdrantClient\n",
        "from pathlib import Path\n",
        "from typing import Optional, Sequence\n",
        "\n",
        "# Add parent directory to path to import from implementation package\n",
        "# Notebooks are in implementation/notebooks/, so we go up two levels to project root\n",
        "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
        "\n",
        "from implementation.classes.movie import BaseMovie\n",
        "from implementation.misc.helpers import normalize_string, create_watch_provider_offering_int\n",
        "from implementation.classes.enums import Genre, MaturityRating, WatchProviderType\n",
        "\n",
        "# PostgreSQL\n",
        "pg = psycopg2.connect(\n",
        "    host=os.getenv(\"POSTGRES_HOST\"),\n",
        "    dbname=os.getenv(\"POSTGRES_DB\"),\n",
        "    user=os.getenv(\"POSTGRES_USER\"),\n",
        "    password=os.getenv(\"POSTGRES_PASSWORD\"),\n",
        ")\n",
        "\n",
        "# # Redis\n",
        "# r = redis.Redis(host=\"localhost\", port=6379, decode_responses=True)\n",
        "\n",
        "# # Qdrant\n",
        "# qdrant = QdrantClient(host=\"localhost\", port=6333)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e04ba2ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LOAD MOVIES\n",
        "\n",
        "json_path = Path(\"../../saved_imdb_movies.json\")\n",
        "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    movies_data = json.load(f)\n",
        "\n",
        "# Convert each dictionary to an IMDBMovie object\n",
        "movies = [BaseMovie(**movie_dict) for movie_dict in movies_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "28319865",
      "metadata": {},
      "outputs": [],
      "source": [
        "# DATABASE METHODS\n",
        "\n",
        "def _execute_write(query: str, params: tuple, fetch_one: bool = False):\n",
        "    \"\"\"Execute a single write statement and optionally return one row.\"\"\"\n",
        "    # Use a context-managed cursor so resources are always released.\n",
        "    with pg.cursor() as cur:\n",
        "        cur.execute(query, params)\n",
        "\n",
        "        if fetch_one:\n",
        "            row = cur.fetchone()\n",
        "            # Commit after fetching so the transaction is persisted.\n",
        "            pg.commit()\n",
        "            return row\n",
        "\n",
        "    # Commit non-returning writes immediately.\n",
        "    pg.commit()\n",
        "    return None\n",
        "\n",
        "\n",
        "def upsert_movie_card(\n",
        "    movie_id: int,\n",
        "    title: str,\n",
        "    year: Optional[int],\n",
        "    poster_url: Optional[str],\n",
        "    release_ts: Optional[int],\n",
        "    runtime_minutes: Optional[int],\n",
        "    maturity_rank: Optional[int],\n",
        "    genre_ids: Sequence[int],\n",
        "    watch_offer_keys: Sequence[int],\n",
        "    audio_language_ids: Sequence[int],\n",
        "    reception_score: Optional[float],\n",
        "    title_token_count: int,\n",
        ") -> None:\n",
        "    \"\"\"Upsert a row in public.movie_card for canonical metadata storage.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO public.movie_card (\n",
        "        movie_id, title, year, poster_url, release_ts, runtime_minutes,\n",
        "        maturity_rank, genre_ids, watch_offer_keys, audio_language_ids,\n",
        "        reception_score, title_token_count, created_at, updated_at\n",
        "    )\n",
        "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, now(), now())\n",
        "    ON CONFLICT (movie_id) DO UPDATE SET\n",
        "        title = EXCLUDED.title,\n",
        "        year = EXCLUDED.year,\n",
        "        poster_url = EXCLUDED.poster_url,\n",
        "        release_ts = EXCLUDED.release_ts,\n",
        "        runtime_minutes = EXCLUDED.runtime_minutes,\n",
        "        maturity_rank = EXCLUDED.maturity_rank,\n",
        "        genre_ids = EXCLUDED.genre_ids,\n",
        "        watch_offer_keys = EXCLUDED.watch_offer_keys,\n",
        "        audio_language_ids = EXCLUDED.audio_language_ids,\n",
        "        reception_score = EXCLUDED.reception_score,\n",
        "        title_token_count = EXCLUDED.title_token_count,\n",
        "        updated_at = now();\n",
        "    \"\"\"\n",
        "    params = (\n",
        "        movie_id,\n",
        "        title,\n",
        "        year,\n",
        "        poster_url,\n",
        "        release_ts,\n",
        "        runtime_minutes,\n",
        "        maturity_rank,\n",
        "        list(genre_ids),\n",
        "        list(watch_offer_keys),\n",
        "        list(audio_language_ids),\n",
        "        reception_score,\n",
        "        title_token_count,\n",
        "    )\n",
        "    _execute_write(query, params)\n",
        "\n",
        "\n",
        "def upsert_lexical_dictionary(norm_str: str) -> int:\n",
        "    \"\"\"Upsert a normalized string in lex.lexical_dictionary and return string_id.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.lexical_dictionary (norm_str, touched_at, created_at)\n",
        "    VALUES (%s, now(), now())\n",
        "    ON CONFLICT (norm_str) DO UPDATE SET\n",
        "        touched_at = now()\n",
        "    RETURNING string_id;\n",
        "    \"\"\"\n",
        "    row = _execute_write(query, (norm_str,), fetch_one=True)\n",
        "    return row[0]\n",
        "\n",
        "\n",
        "def upsert_title_token_string(string_id: int, norm_str: str) -> None:\n",
        "    \"\"\"Upsert a title-token lookup row in lex.title_token_strings.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.title_token_strings (string_id, norm_str)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (string_id) DO UPDATE SET\n",
        "        norm_str = EXCLUDED.norm_str;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (string_id, norm_str))\n",
        "\n",
        "\n",
        "def insert_title_token_posting(term_id: int, movie_id: int) -> None:\n",
        "    \"\"\"Insert one title-token posting row into lex.inv_title_token_postings.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.inv_title_token_postings (term_id, movie_id)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (term_id, movie_id) DO NOTHING;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (term_id, movie_id))\n",
        "\n",
        "\n",
        "def insert_person_posting(term_id: int, movie_id: int) -> None:\n",
        "    \"\"\"Insert one person posting row into lex.inv_person_postings.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.inv_person_postings (term_id, movie_id)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (term_id, movie_id) DO NOTHING;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (term_id, movie_id))\n",
        "\n",
        "\n",
        "def insert_character_posting(term_id: int, movie_id: int) -> None:\n",
        "    \"\"\"Insert one character posting row into lex.inv_character_postings.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.inv_character_postings (term_id, movie_id)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (term_id, movie_id) DO NOTHING;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (term_id, movie_id))\n",
        "\n",
        "\n",
        "def insert_studio_posting(term_id: int, movie_id: int) -> None:\n",
        "    \"\"\"Insert one studio posting row into lex.inv_studio_postings.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.inv_studio_postings (term_id, movie_id)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (term_id, movie_id) DO NOTHING;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (term_id, movie_id))\n",
        "\n",
        "\n",
        "def upsert_genre_dictionary(genre_id: int, name: str) -> None:\n",
        "    \"\"\"Upsert a genre lookup row in lex.genre_dictionary.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.genre_dictionary (genre_id, name)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (genre_id) DO UPDATE SET\n",
        "        name = EXCLUDED.name;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (genre_id, name))\n",
        "\n",
        "\n",
        "def upsert_provider_dictionary(provider_id: int, name: str) -> None:\n",
        "    \"\"\"Upsert a provider lookup row in lex.provider_dictionary.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.provider_dictionary (provider_id, name)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (provider_id) DO UPDATE SET\n",
        "        name = EXCLUDED.name;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (provider_id, name))\n",
        "\n",
        "\n",
        "def upsert_watch_method_dictionary(method_id: int, name: str) -> None:\n",
        "    \"\"\"Upsert a watch-method lookup row in lex.watch_method_dictionary.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.watch_method_dictionary (method_id, name)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (method_id) DO UPDATE SET\n",
        "        name = EXCLUDED.name;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (method_id, name))\n",
        "\n",
        "\n",
        "def upsert_maturity_dictionary(maturity_rank: int, label: str) -> None:\n",
        "    \"\"\"Upsert a maturity-rating lookup row in lex.maturity_dictionary.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.maturity_dictionary (maturity_rank, label)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (maturity_rank) DO UPDATE SET\n",
        "        label = EXCLUDED.label;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (maturity_rank, label))\n",
        "\n",
        "def upsert_language_dictionary(language_id: int, name: str) -> None:\n",
        "    \"\"\"Upsert a language lookup row in lex.language_dictionary.\"\"\"\n",
        "    query = \"\"\"\n",
        "    INSERT INTO lex.language_dictionary (language_id, name)\n",
        "    VALUES (%s, %s)\n",
        "    ON CONFLICT (language_id) DO UPDATE SET\n",
        "        name = EXCLUDED.name;\n",
        "    \"\"\"\n",
        "    _execute_write(query, (language_id, name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b6744bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ingest a single movie object\n",
        "\n",
        "def ingest_movie(movie: BaseMovie) -> None:\n",
        "    \"\"\"Ingest one BaseMovie into movie_card plus all lexical posting tables.\"\"\"\n",
        "    from datetime import datetime, timezone\n",
        "\n",
        "    def upsert_phrase_term(value: str) -> int | None:\n",
        "        \"\"\"Normalize a phrase and upsert it into lexical_dictionary.\"\"\"\n",
        "        normalized = normalize_string(value)\n",
        "        if not normalized:\n",
        "            return None\n",
        "        return upsert_lexical_dictionary(normalized)\n",
        "\n",
        "    # ================================\n",
        "    # PHASE 1: CANONICAL INGESTION\n",
        "    # ================================\n",
        "\n",
        "    movie_id = int(getattr(movie, \"tmdb_id\") or None)\n",
        "    if movie_id is None:\n",
        "        raise ValueError(\"Movie ingestion failed: ID is required but not found.\")\n",
        "\n",
        "    title = str(getattr(movie, \"title\") or None)\n",
        "    if title is None:\n",
        "        raise ValueError(\"Movie ingestion failed: Title is required but not found.\")\n",
        "\n",
        "    release_date = getattr(movie, \"release_date\")\n",
        "    if not isinstance(release_date, str):\n",
        "        raise ValueError(\"Movie ingestion failed: Release date is required but not found.\")\n",
        "\n",
        "    year: Optional[int] = None\n",
        "    release_ts: Optional[int] = None\n",
        "    if release_date:\n",
        "        try:\n",
        "            parsed_release = datetime.strptime(release_date, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "            year = parsed_release.year\n",
        "            release_ts = int(parsed_release.timestamp())\n",
        "        except ValueError:\n",
        "            raise ValueError(\"Movie ingestion failed: Release date is required but an error occurred during parsing.\")\n",
        "\n",
        "    # Default value used here because BaseMovie does not define poster_url.\n",
        "    poster_url: Optional[str] = getattr(movie, \"poster_url\", None)\n",
        "\n",
        "    runtime_value = getattr(movie, \"duration\", None)\n",
        "    if isinstance(runtime_value, int):\n",
        "        runtime_minutes: Optional[int] = runtime_value\n",
        "    else:\n",
        "        raise ValueError(\"Movie ingestion failed: Duration is required but not found.\")\n",
        "\n",
        "    maturity_rating, maturity_rank = movie.maturity_rating_and_rank()\n",
        "    # Keep lookup table aligned with encoded maturity ranks.\n",
        "    upsert_maturity_dictionary(maturity_rank, maturity_rating)\n",
        "\n",
        "    raw_genres = getattr(movie, \"genres\", [])\n",
        "    if not isinstance(raw_genres, list):\n",
        "        # Default value used here because BaseMovie may not provide genres.\n",
        "        raw_genres = []\n",
        "\n",
        "    genre_ids: list[int] = []\n",
        "    for genre_name in raw_genres:\n",
        "        normalized_genre = normalize_string(str(genre_name))\n",
        "        if not normalized_genre:\n",
        "            continue\n",
        "        # Derive genre ID from the shared lexical dictionary.\n",
        "        genre_id = upsert_lexical_dictionary(normalized_genre)\n",
        "        genre_ids.append(genre_id)\n",
        "        # Keep lookup table populated for debugging/admin views.\n",
        "        upsert_genre_dictionary(genre_id, str(genre_name))\n",
        "\n",
        "    raw_languages = getattr(movie, \"languages\", [])\n",
        "    if not isinstance(raw_languages, list):\n",
        "        # Default value used here because BaseMovie may not provide languages.\n",
        "        raw_languages = []\n",
        "\n",
        "    audio_language_ids: list[int] = []\n",
        "    for language in raw_languages:\n",
        "        normalized_language = normalize_string(str(language))\n",
        "        if not normalized_language:\n",
        "            continue\n",
        "        # Derive language ID from the shared lexical dictionary.\n",
        "        language_id = upsert_lexical_dictionary(normalized_language)\n",
        "        audio_language_ids.append(language_id)\n",
        "        # Keep lookup table populated for debugging/admin views.\n",
        "        upsert_language_dictionary(language_id, str(language))\n",
        "\n",
        "    raw_providers = getattr(movie, \"watch_providers\", [])\n",
        "    if not isinstance(raw_providers, list):\n",
        "        # Default value used here because BaseMovie may not provide watch_providers.\n",
        "        raw_providers = []\n",
        "\n",
        "    watch_offer_key_set: set[int] = set()\n",
        "    for provider in raw_providers:\n",
        "        provider_name = str(getattr(provider, \"name\", \"\") or \"\")\n",
        "        normalized_provider = normalize_string(provider_name)\n",
        "        if not normalized_provider:\n",
        "            continue\n",
        "\n",
        "        # Derive provider ID from the shared lexical dictionary.\n",
        "        provider_id = upsert_lexical_dictionary(normalized_provider)\n",
        "        # Keep lookup table populated for debugging/admin views.\n",
        "        upsert_provider_dictionary(provider_id, provider_name)\n",
        "\n",
        "        provider_types = getattr(provider, \"types\", [])\n",
        "        if not isinstance(provider_types, list):\n",
        "            # Default value used here because WatchProvider may not provide types.\n",
        "            provider_types = []\n",
        "\n",
        "        for provider_type in provider_types:\n",
        "            # provider_type is already an integer from WatchProviderType enum.\n",
        "            method_id = int(provider_type)\n",
        "            \n",
        "            # Get the enum member to fetch its string name for the dictionary.\n",
        "            try:\n",
        "                watch_provider_type = WatchProviderType(method_id)\n",
        "            except ValueError:\n",
        "                continue\n",
        "            \n",
        "            upsert_watch_method_dictionary(method_id, str(watch_provider_type))\n",
        "\n",
        "            watch_offer_key = create_watch_provider_offering_int(provider_id, method_id)\n",
        "            watch_offer_key_set.add(watch_offer_key)\n",
        "\n",
        "    watch_offer_keys = sorted(watch_offer_key_set)\n",
        "\n",
        "    reception_score = movie.reception_score()\n",
        "\n",
        "    title_tokens = movie.normalized_title_tokens()\n",
        "    title_token_count = len(title_tokens)\n",
        "\n",
        "    # Upsert canonical movie-card metadata first so other systems can reference it.\n",
        "    upsert_movie_card(\n",
        "        movie_id=movie_id,\n",
        "        title=title,\n",
        "        year=year,\n",
        "        poster_url=poster_url,\n",
        "        release_ts=release_ts,\n",
        "        runtime_minutes=runtime_minutes,\n",
        "        maturity_rank=maturity_rank,\n",
        "        genre_ids=genre_ids,\n",
        "        watch_offer_keys=watch_offer_keys,\n",
        "        audio_language_ids=audio_language_ids,\n",
        "        reception_score=reception_score,\n",
        "        title_token_count=title_token_count,\n",
        "    )\n",
        "\n",
        "    # ================================\n",
        "    # PHASE 2: LEXICAL INGESTION\n",
        "    # ================================\n",
        "\n",
        "    # Title token ingestion: dictionary + title_token_strings + postings.\n",
        "    for token in title_tokens:\n",
        "        term_id = upsert_lexical_dictionary(token)\n",
        "        upsert_title_token_string(term_id, token)\n",
        "        insert_title_token_posting(term_id, movie_id)\n",
        "\n",
        "    # Person phrase ingestion across actors/directors/writers/composers/producers.\n",
        "    raw_people_lists = [\n",
        "        getattr(movie, \"actors\", []),\n",
        "        getattr(movie, \"directors\", []),\n",
        "        getattr(movie, \"writers\", []),\n",
        "        getattr(movie, \"composers\", []),\n",
        "        getattr(movie, \"producers\", []),\n",
        "    ]\n",
        "\n",
        "    people_phrases: set[str] = set()\n",
        "    for people_list in raw_people_lists:\n",
        "        if not isinstance(people_list, list):\n",
        "            # Default value used here because BaseMovie may not provide a person list.\n",
        "            people_list = []\n",
        "        for name in people_list:\n",
        "            normalized_name = normalize_string(str(name))\n",
        "            if normalized_name:\n",
        "                people_phrases.add(normalized_name)\n",
        "\n",
        "    for person_phrase in people_phrases:\n",
        "        term_id = upsert_lexical_dictionary(person_phrase)\n",
        "        insert_person_posting(term_id, movie_id)\n",
        "\n",
        "    # Character phrase ingestion.\n",
        "    raw_characters = getattr(movie, \"characters\", [])\n",
        "    if not isinstance(raw_characters, list):\n",
        "        # Default value used here because BaseMovie may not provide characters.\n",
        "        raw_characters = []\n",
        "\n",
        "    for character in raw_characters:\n",
        "        term_id = upsert_phrase_term(str(character))\n",
        "        if term_id is not None:\n",
        "            insert_character_posting(term_id, movie_id)\n",
        "\n",
        "    # Studio phrase ingestion.\n",
        "    raw_studios = getattr(movie, \"production_companies\", [])\n",
        "    if not isinstance(raw_studios, list):\n",
        "        # Default value used here because BaseMovie may not provide production_companies.\n",
        "        raw_studios = []\n",
        "\n",
        "    for studio in raw_studios:\n",
        "        term_id = upsert_phrase_term(str(studio))\n",
        "        if term_id is not None:\n",
        "            insert_studio_posting(term_id, movie_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "88b62cde",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingesting movie: zootopia\n"
          ]
        }
      ],
      "source": [
        "movie_to_ingest = movies[1]\n",
        "\n",
        "print(f\"Ingesting movie: {movie_to_ingest.title}\")\n",
        "\n",
        "ingest_movie(movie_to_ingest)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

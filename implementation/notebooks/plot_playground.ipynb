{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb8b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import from implementation package\n",
    "# Notebooks are in implementation/notebooks/, so we go up two levels to project root\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "\n",
    "from implementation.vectorize import create_plot_analysis_vector_text, create_plot_events_vector_text\n",
    "from openai import OpenAI\n",
    "from implementation.llm_generations import generate_plot_events_metadata, generate_plot_analysis_metadata, generate_plot_metadata\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Optional\n",
    "from pathlib import Path\n",
    "from implementation.movie import IMDBMovie\n",
    "from implementation.schemas import PlotAnalysisMetadata\n",
    "\n",
    "# Load environment variables (for API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key from environment and initialize client once at module load\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\n",
    "        \"OPENAI_API_KEY environment variable not set. \"\n",
    "        \"Please set it before importing this module.\"\n",
    "    )\n",
    "\n",
    "# Initialize OpenAI client - created once when module is loaded\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b312ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MOVIES\n",
    "\n",
    "json_path = Path(\"../../saved_imdb_movies.json\")\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    movies_data = json.load(f)\n",
    "\n",
    "# Convert each dictionary to an IMDBMovie object\n",
    "movies = [IMDBMovie(**movie_dict) for movie_dict in movies_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad76b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ferris bueller's day off\n",
      "1: zootopia\n",
      "2: school of rock\n",
      "3: frozen\n",
      "4: the princess bride\n",
      "5: coco\n",
      "6: klaus\n",
      "7: up\n",
      "8: mulan\n",
      "9: shrek\n",
      "10: the year without a santa claus\n",
      "11: mad max: fury road\n",
      "12: raiders of the lost ark\n",
      "13: the dark knight\n",
      "14: john wick\n",
      "15: captain america: the first avenger\n",
      "16: spider-man: across the spider-verse\n",
      "17: avengers: endgame\n",
      "18: star wars\n",
      "19: harry potter and the philosopher's stone\n",
      "20: the lord of the rings: the fellowship of the ring\n",
      "21: gladiator\n",
      "22: inception\n",
      "23: the matrix\n",
      "24: interstellar\n",
      "25: blade runner 2049\n",
      "26: jurassic park\n",
      "27: arrival\n",
      "28: hereditary\n",
      "29: the shining\n",
      "30: insidious\n",
      "31: terrifier 3\n",
      "32: saw\n",
      "33: se7en\n",
      "34: parasite\n",
      "35: get out\n",
      "36: american psycho\n",
      "37: fight club\n",
      "38: titanic\n",
      "39: forrest gump\n",
      "40: past lives\n",
      "41: the pianist\n",
      "42: the notebook\n",
      "43: 50 first dates\n",
      "44: leap year\n",
      "45: fifty shades of grey\n",
      "46: murder on the orient express\n",
      "47: everything everywhere all at once\n",
      "48: scott pilgrim vs. the world\n",
      "49: the naked gun: from the files of police squad!\n"
     ]
    }
   ],
   "source": [
    "for index, movie in enumerate(movies):\n",
    "    print(f\"{index}: {movie.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff0ac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2018, Clint Barton (Hawkeye) practices archery with his daughter Lila at his rural homestead; she disintegrates into ash during Thanos' snap, leaving Clint devastated. Three weeks later Tony Stark and Nebula are adrift aboard the Guardians' ship Benatar; Tony records a goodbye to Pepper Potts as supplies run out. Carol Danvers (Captain Marvel) finds and returns them to Earth. Tony reunites with Pepper, Steve Rogers, Natasha Romanoff, Bruce Banner and James Rhodes; Rocket joins Nebula as the Guardians mourn. The team locates Thanos' garden ship and ambushes him; they cut off his gauntlet only to learn Thanos destroyed the Infinity Stones to prevent reuse. Thor beheads Thanos. With the stones gone there is no way to reverse the snap. Five years pass. Steve runs a support group; Tony and Pepper are married with daughter Morgan; Clint has become Ronin, killing criminals worldwide; Scott Lang (Ant-Man) escapes the quantum realm and reunites with his now-teenage daughter Cassie.\n",
      "Scott proposes using the quantum realm to time-travel and retrieve past Infinity Stones. Initially reluctant, Tony develops a time-space GPS and, after reconciling with Steve, joins the plan. Banner (as Smart Hulk) stabilizes the quantum tunnel; the Avengers recruit Thor (now depressed and living in New Asgard), Rocket, and Clint. They have limited Pym particles and split into teams to collect stones from specific past moments: 2012 New York (Space, Mind, Time), 2013 Asgard (Reality/Aether), 2014 Morag (Power), and 2014 Vormir (Soul).\n",
      "In 2012 New York, Banner meets the Ancient One and obtains the Time Stone after explaining Doctor Strange's future choice. At Stark Tower, Tony and Scott attempt to steal the tesseract; Loki grabs it and escapes into the past. Steve obtains Loki's scepter by impersonating a Hydra agent and fights his 2012 self. Tony and Steve then travel to 1970 to get more Pym particles and the tesseract; Steve briefly sees Peggy Carter and Tony reconciles with his father Howard, gaining emotional closure.\n",
      "On Asgard (2013), Thor confronts his mother Frigga, who counsels him; Rocket extracts the Aether from Jane Foster, and Thor proves he is still worthy by summoning Mjolnir. On Morag (2014) Nebula and Rhodes wait for Star-Lord; Nebula's past self becomes entangled with her future self's memories, creating a network that allows 2014 Thanos to learn of the time heist. On Vormir (2014), Red Skull informs Natasha and Clint that retrieving the Soul Stone requires a sacrifice of a loved one. After a struggle where both attempt to sacrifice themselves, Natasha throws herself off the cliff so Clint can take the Soul Stone.\n",
      "The teams return to 2023 with the stones; Natasha's death is permanent. Banner uses a Stark-made gauntlet and snaps to restore everyone vanished in 2018, badly injuring his arm but succeeding. However, past Nebula (2014) replaced future Nebula during travel and betrays the Avengers by opening a portal to her father; 2014 Thanos arrives with his army aboard Sanctuary II and destroys the Avengers compound with missile barrages.\n",
      "Thanos' forces attack; a massive battle unfolds. Reinforcements arrive through sorcerer portals: sorcerers, Wakandan armies, Asgardians, and resurrected heroes from Titan and San Francisco. Thanos gains the gauntlet during the fight, but Doctor Strange signals to Tony that only one timeline leads to victory. Tony's suit transfers the stones to his armor; he snaps, erasing Thanos and his army but fatally wounded by the stones' energy. Tony dies surrounded by Pepper, Peter Parker and Rhodes. The vanished are restored worldwide; celebrations follow.\n",
      "At Tony's funeral the heroes and allies mourn. Thor appoints Valkyrie ruler of New Asgard and joins the Guardians. Steve returns the stones and Mjolnir to their original timelines but remains in the past to live a life with Peggy Carter; he reappears as an old man who passes his shield to Sam Wilson, making Sam the new Captain America. The film ends with Steve dancing with Peggy in the past.\n",
      "2018â€“2023, Earth and various past MCU locations via time travel\n",
      "Steve Rogers: Former Captain America leading the Avengers' plan to retrieve the Infinity Stones. Motivations: Restore the vanished and reunite the team by returning the stones to reverse Thanos' snap.\n",
      "Tony Stark: Genius billionaire inventor who builds the time-travel tech and ultimately uses the stones. Motivations: Protect his family and save the universe, even at the cost of his life.\n",
      "Natasha Romanoff: Avenger and mission leader who sacrifices herself to obtain the Soul Stone. Motivations: Bring back the vanished by any means, accepting personal sacrifice for the greater good.\n",
      "Clint Barton: Hawkeye turned vengeful Ronin after losing his family, later returns to the team. Motivations: Avenge and prevent further loss; recover what was taken from him and others.\n",
      "Thanos: Mad Titan who destroyed half of all life in 2018 and later attempts to remake the universe. Motivations: Enforce his vision of balance by using the Infinity Stones to reshape existence.\n"
     ]
    }
   ],
   "source": [
    "movie = movies[17]\n",
    "\n",
    "print(create_plot_events_vector_text(movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d43490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plot metadata for raiders of the lost ark\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m movie2 = movies[\u001b[32m12\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m disregard, results = \u001b[43mgenerate_plot_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmovie2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverview\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmovie2\u001b[49m\u001b[43m.\u001b[49m\u001b[43moverview\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_summaries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmovie2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug_plot_summaries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_synopses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmovie2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug_synopses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_keywords\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmovie2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_keywords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatured_reviews\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmovie2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeatured_reviews\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m plot_events_metadata, plot_analysis_metadata = results\n\u001b[32m     14\u001b[39m movie2.plot_events_metadata = plot_events_metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/implementation/llm_generations.py:334\u001b[39m, in \u001b[36mgenerate_plot_metadata\u001b[39m\u001b[34m(title, overview, plot_summaries, plot_synopses, plot_keywords, featured_reviews)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# Time the plot events metadata generation\u001b[39;00m\n\u001b[32m    333\u001b[39m start_time_events = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m plot_events_metadata = \u001b[43mgenerate_plot_events_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverview\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverview\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_keywords\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplot_keywords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_summaries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplot_summaries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_synopses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplot_synopses\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m end_time_events = time.perf_counter()\n\u001b[32m    342\u001b[39m events_duration = end_time_events - start_time_events\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/implementation/llm_generations.py:61\u001b[39m, in \u001b[36mgenerate_plot_events_metadata\u001b[39m\u001b[34m(title, overview, plot_keywords, plot_summaries, plot_synopses)\u001b[39m\n\u001b[32m     56\u001b[39m user_prompt = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(plot_info_parts)\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Generate response using gpt-5-nano with lowest thinking setting\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Using .parse() for structured output - automatically validates and parses response\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Note: reasoning_effort=\"minimal\" uses the minimum reasoning capacity for faster responses\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-5-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPLOT_EVENTS_SYSTEM_PROMPT\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPlotEventsMetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mminimal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     70\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Extract the parsed response - OpenAI automatically validates structure matches PlotMetadata\u001b[39;00m\n\u001b[32m     73\u001b[39m message = response.choices[\u001b[32m0\u001b[39m].message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:184\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    179\u001b[39m         response_format=response_format,\n\u001b[32m    180\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    181\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/movie-finder-rag/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "movie2 = movies[12]\n",
    "\n",
    "disregard, results = generate_plot_metadata(\n",
    "    title=movie2.title,\n",
    "    overview=movie2.overview,\n",
    "    plot_summaries=movie2.debug_plot_summaries,\n",
    "    plot_synopses=movie2.debug_synopses,\n",
    "    plot_keywords=movie2.plot_keywords,\n",
    "    featured_reviews=movie2.featured_reviews,\n",
    ")\n",
    "\n",
    "plot_events_metadata, plot_analysis_metadata = results\n",
    "\n",
    "movie2.plot_events_metadata = plot_events_metadata\n",
    "movie2.plot_analysis_metadata = plot_analysis_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a2307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4 movies, generating metadata twice for each...\n",
      "Generating plot metadata for frozen\n",
      "Generating plot metadata for raiders of the lost ark\n",
      "Generating plot metadata for titanic\n",
      "Generating plot metadata for murder on the orient express\n",
      "Plot events metadata for raiders of the lost ark (completed in 14.68 seconds):\n",
      "Plot events metadata for murder on the orient express (completed in 19.85 seconds):\n",
      "Plot events metadata for titanic (completed in 21.07 seconds):\n",
      "Plot events metadata for frozen (completed in 33.46 seconds):\n",
      "\n",
      "Plot analysis metadata for raiders of the lost ark (completed in 22.40 seconds):\n",
      "Generating plot metadata for raiders of the lost ark\n",
      "\n",
      "Plot analysis metadata for titanic (completed in 25.85 seconds):\n",
      "Generating plot metadata for titanic\n",
      "\n",
      "Plot analysis metadata for murder on the orient express (completed in 28.07 seconds):\n",
      "Generating plot metadata for murder on the orient express\n",
      "\n",
      "Plot analysis metadata for frozen (completed in 19.44 seconds):\n",
      "Generating plot metadata for frozen\n",
      "Plot events metadata for raiders of the lost ark (completed in 16.17 seconds):\n",
      "Plot events metadata for titanic (completed in 15.63 seconds):\n",
      "Plot events metadata for murder on the orient express (completed in 19.45 seconds):\n",
      "Plot events metadata for frozen (completed in 16.18 seconds):\n",
      "\n",
      "Plot analysis metadata for raiders of the lost ark (completed in 27.70 seconds):\n",
      "[1/4] âœ“ raiders of the lost ark - Saved 2 results to file\n",
      "\n",
      "Plot analysis metadata for titanic (completed in 23.88 seconds):\n",
      "[2/4] âœ“ titanic - Saved 2 results to file\n",
      "\n",
      "Plot analysis metadata for murder on the orient express (completed in 26.04 seconds):\n",
      "[3/4] âœ“ murder on the orient express - Saved 2 results to file\n",
      "\n",
      "Plot analysis metadata for frozen (completed in 28.20 seconds):\n",
      "[4/4] âœ“ frozen - Saved 2 results to file\n",
      "\n",
      "Done! Successfully processed 4 movies\n"
     ]
    }
   ],
   "source": [
    "# GENERATE A BUNCH OF RESULTS SO I CAN COMPARE LATER\n",
    "\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "indices = [3,12,38,46]\n",
    "\n",
    "movies_to_save = [movies[i] for i in indices]\n",
    "\n",
    "def process_movie_twice(movie: IMDBMovie) -> tuple[str, list[dict], bool]:\n",
    "    \"\"\"\n",
    "    Process a single movie by generating plot metadata twice and save to file.\n",
    "    \n",
    "    Args:\n",
    "        movie: The IMDBMovie object to process\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (movie_title, list_of_results, success) where each result is a dict\n",
    "        containing both plot_events_metadata and plot_analysis_metadata\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Generate plot metadata twice for this movie\n",
    "    for run_num in range(2):\n",
    "        try:\n",
    "            # Call generate_plot_metadata - it returns a tuple with status and data\n",
    "            status, metadata_tuple = generate_plot_metadata(\n",
    "                title=movie.title,\n",
    "                overview=movie.overview,\n",
    "                plot_keywords=movie.plot_keywords,\n",
    "                plot_summaries=movie.debug_plot_summaries,\n",
    "                plot_synopses=movie.debug_synopses,\n",
    "                featured_reviews=movie.featured_reviews,\n",
    "            )\n",
    "            \n",
    "            if metadata_tuple is not None:\n",
    "                plot_events_metadata, plot_analysis_metadata = metadata_tuple\n",
    "                # Store both results in a single dict\n",
    "                result = {\n",
    "                    \"run\": run_num + 1,\n",
    "                    \"title\": movie.title,\n",
    "                    \"plot_events_metadata\": plot_events_metadata.model_dump(),\n",
    "                    \"plot_analysis_metadata\": plot_analysis_metadata.model_dump()\n",
    "                }\n",
    "                results.append(result)\n",
    "            else:\n",
    "                print(f\"Warning: Failed to generate metadata for {movie.title} (run {run_num + 1})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {movie.title} (run {run_num + 1}): {e}\")\n",
    "    \n",
    "    # Save results to file for this movie (2 JSON objects, one per line)\n",
    "    if results:\n",
    "        # Create a safe filename from the movie title\n",
    "        safe_filename = \"\".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in movie.title)\n",
    "        safe_filename = safe_filename.replace(' ', '_').lower()\n",
    "        output_file = f\"./{safe_filename}_v2.jsonl\"\n",
    "        \n",
    "        try:\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                for result in results:\n",
    "                    f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "            return (movie.title, results, True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving file for {movie.title}: {e}\")\n",
    "            return (movie.title, results, False)\n",
    "    else:\n",
    "        return (movie.title, results, False)\n",
    "\n",
    "# Process all movies in parallel\n",
    "print(f\"Processing {len(movies_to_save)} movies, generating metadata twice for each...\")\n",
    "successful_movies = []\n",
    "failed_movies = []\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize across movies\n",
    "# Each movie will be processed twice sequentially, but different movies process in parallel\n",
    "# Each movie's results are saved to its own file during processing\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Submit all tasks\n",
    "    future_to_movie = {\n",
    "        executor.submit(process_movie_twice, movie): movie \n",
    "        for movie in movies_to_save\n",
    "    }\n",
    "    \n",
    "    # Process completed tasks as they finish\n",
    "    completed = 0\n",
    "    for future in as_completed(future_to_movie):\n",
    "        movie = future_to_movie[future]\n",
    "        completed += 1\n",
    "        \n",
    "        try:\n",
    "            movie_title, results, success = future.result()\n",
    "            if success:\n",
    "                successful_movies.append(movie_title)\n",
    "                print(f\"[{completed}/{len(movies_to_save)}] âœ“ {movie_title} - Saved {len(results)} results to file\")\n",
    "            else:\n",
    "                failed_movies.append(movie_title)\n",
    "                print(f\"[{completed}/{len(movies_to_save)}] âœ— {movie_title} - Failed to save results\")\n",
    "        except Exception as e:\n",
    "            failed_movies.append(movie.title)\n",
    "            print(f\"[{completed}/{len(movies_to_save)}] âœ— {movie.title} - Error: {e}\")\n",
    "\n",
    "print(f\"\\nDone! Successfully processed {len(successful_movies)} movies\")\n",
    "if failed_movies:\n",
    "    print(f\"Failed: {len(failed_movies)} movies\")\n",
    "    for movie_title in failed_movies:\n",
    "        print(f\"  - {movie_title}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c7c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated results for raiders of the lost ark\n",
      "========== V1 RESULTS ==========\n",
      "In 1936 an archaeologist is recruited to beat a rival authoritarian force to a legendary sacred artifact, decoding clues, infiltrating digs, rescuing allies, and ultimately witnessing the artifact destroy those who exploited it; the story is a race-against-evil treasure hunt that punishes hubris and affirms duty and respect for the sacred.\n",
      "Race to secure supernatural artifact\n",
      "Treasure-hunt adventure, Pulp action-adventure\n",
      "large-scale conflict\n",
      "linear narrative\n",
      "recommitment to duty, hubris punished\n",
      "quest/adventure\n",
      "Good versus ideological evil, Sacred power versus greed\n",
      "Greed invites destruction, Respect sacred limits','Duty over personal gain\n",
      "\n",
      "An archaeologist races to secure a powerful ancient artifact before a fascist rival can exploit its power, assembling a team, solving map-room puzzles, surviving trap-filled tombs and ambushes, and rekindling a past relationship; the race ends when the artifact's supernatural power destroys its abusers and authorities sequester the object, underscoring the danger of seeking and wielding ancient power.\n",
      "Race to secure a powerful artifact\n",
      "Action-adventure, Treasure hunt\n",
      "large-scale conflict\n",
      "linear narrative\n",
      "reluctant heroism, reconciliation with past\n",
      "quest/adventure\n",
      "Power and moral responsibility, Discovery versus exploitation\n",
      "Power demands restraint, Knowledge can be weaponized\n",
      "\n",
      "========== V2 RESULTS ==========\n",
      "An intrepid archaeologist is hired to race a fascist regime to recover a sacred, potentially world-altering artifact, fighting traps, rival treasure hunters, and enemy operatives; the artifact's unleashed supernatural power annihilates the villains and the dangerous relic is ultimately secured and hidden. The story is driven by a relentless race for sacred power and the clash between political ambition and individual courage.\n",
      "Race to secure supernatural artifact\n",
      "Pulp action-adventure, Treasure-hunt thriller\n",
      "large-scale conflict\n",
      "linear narrative\n",
      "reaffirmation of duty, reconciliation with past\n",
      "quest/adventure\n",
      "Sacred power vs political ambition, Individual courage vs totalitarianism\n",
      "Power invites corruption, Some forces are best sealed\n",
      "\n",
      "In 1936 a roguish academic is hired by government intelligence to race a fascist regime's agents to locate a legendary sacred artifact; through globe-trotting set pieces, rival treasure-seekers, a lost key, and daring recoveries he locates the site, recovers the artifact, and prevents its exploitation. The film frames a pulp adventure about the race for supernatural power and the dangers of hubris, ending with the artifact's destructive revelation and its resealing and concealment by authorities.\n",
      "Race to secure supernatural artifact\n",
      "Pulp adventure, Treasure-hunt thriller\n",
      "large scale conflict\n",
      "linear narrative\n",
      "skeptic tested by faith, ambition leads to ruin\n",
      "quest/adventure\n",
      "Power's corrupting allure, Preservation vs exploitation of knowledge\n",
      "Hubris destroys seekers, Protect dangerous knowledge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DIRECT VERSION COMPARISON\n",
    "\n",
    "movie = movies[12]#[3,12,38,46]\n",
    "\n",
    "safe_filename = \"\".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in movie.title)\n",
    "safe_filename = safe_filename.replace(' ', '_').lower()\n",
    "output_file_v1 = f\"./{safe_filename}.jsonl\"\n",
    "output_file_v2 = f\"./{safe_filename}_v2.jsonl\"\n",
    "\n",
    "with open(output_file_v1, \"r\", encoding=\"utf-8\") as f:\n",
    "    v1_data = []\n",
    "    for line_no, line in enumerate(f, start=1):\n",
    "        line = line.strip()\n",
    "        if not line:  # skip blank lines\n",
    "            continue\n",
    "        try:\n",
    "            v1_data.append(json.loads(line))\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Invalid JSON on line {line_no}: {e}\") from e\n",
    "    v1_data = [PlotAnalysisMetadata(**v1d['plot_analysis_metadata']) for v1d in v1_data]\n",
    "\n",
    "with open(output_file_v2, \"r\", encoding=\"utf-8\") as f:\n",
    "    v2_data = []\n",
    "    for line_no, line in enumerate(f, start=1):\n",
    "        line = line.strip()\n",
    "        if not line:  # skip blank lines\n",
    "            continue\n",
    "        try:\n",
    "            v2_data.append(json.loads(line))\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Invalid JSON on line {line_no}: {e}\") from e\n",
    "    v2_data = [PlotAnalysisMetadata(**v2d['plot_analysis_metadata']) for v2d in v2_data]\n",
    "\n",
    "print(f\"Generated results for {movie.title}\")\n",
    "print(\"========== V1 RESULTS ==========\")\n",
    "for result in v1_data:\n",
    "    print(result)\n",
    "    print()\n",
    "print(\"========== V2 RESULTS ==========\")\n",
    "for result in v2_data:\n",
    "    print(result)\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441fe2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 1930s a resourceful archaeologist is recruited to race rival ideological forces to recover a powerful sacred relic; after locating it amid betrayals and exotic set pieces the relic is seized and opened by the antagonists, whose hubris unleashes supernatural destruction, exposing the moral cost of trying to weaponize sacred power and forcing restraint.\n",
      "Race to secure a powerful relic: A timed contest to recover a supernatural artifact drives every major beat: the protagonist and antagonists race to secure a relic whose possession promises decisive power.\n",
      "Pulp action-adventure, Treasure hunt\n",
      "global conflict\n",
      "linear narrative\n",
      "reluctant hero: A pragmatic, self-reliant scholar grows into a decisive protector who prioritizes preventing ideological misuse of a sacred power over personal gain.\n",
      "ideological hubris: A collaborator driven by ambition and ideology pursues control of the relic and is consumed by hubris, meeting annihilation when the power is unleashed.\n",
      "quest/adventure\n",
      "Ambition vs moral cost: The film centers on the pursuit of power and shows how ambition to possess decisive force entails moral and destructive costs.\n",
      "Sacred power and hubris: It contrasts reverence for the sacred/unknown with the catastrophic consequences of trying to weaponize divine power.\n",
      "Ambition breeds destruction: The antagonists' attempt to seize and exploit a sacred relic directly leads to their destruction, demonstrating that unchecked ambition invites ruin.\n",
      "Respect sacred limits: Survivors' restraint and the final secret storage imply that some forces must be treated with reverence rather than possession.\n",
      "\n",
      "Core Engine: (Race to secure a powerful relic) A timed contest to recover a supernatural artifact drives every major beat: the protagonist and antagonists race to secure a relic whose possession promises decisive power.\n",
      "\n",
      "(Protagonist (archaeologist)) reluctant hero: A pragmatic, self-reliant scholar grows into a decisive protector who prioritizes preventing ideological misuse of a sacred power over personal gain.\n",
      "\n",
      "(Antagonist (rival/collaborator)) ideological hubris: A collaborator driven by ambition and ideology pursues control of the relic and is consumed by hubris, meeting annihilation when the power is unleashed.\n",
      "\n",
      "Ambition vs moral cost: The film centers on the pursuit of power and shows how ambition to possess decisive force entails moral and destructive costs.\n",
      "\n",
      "Sacred power and hubris: It contrasts reverence for the sacred/unknown with the catastrophic consequences of trying to weaponize divine power.\n",
      "\n",
      "Ambition breeds destruction: The antagonists' attempt to seize and exploit a sacred relic directly leads to their destruction, demonstrating that unchecked ambition invites ruin.\n",
      "\n",
      "Respect sacred limits: Survivors' restraint and the final secret storage imply that some forces must be treated with reverence rather than possession.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(movie2.plot_analysis_metadata)\n",
    "print()\n",
    "\n",
    "pmd = movie2.plot_analysis_metadata\n",
    "print(f\"Core Engine: ({pmd.core_engine.core_engine_label}) {pmd.core_engine.explanation_and_justification}\")\n",
    "print()\n",
    "\n",
    "for arc in pmd.character_arcs:\n",
    "    print(f\"({arc.character_name}) {arc.arc_transformation_label}: {arc.arc_transformation_description}\")\n",
    "    print()\n",
    "\n",
    "for theme in pmd.themes_primary:\n",
    "    print(f\"{theme.theme_label}: {theme.explanation_and_justification}\")\n",
    "    print()\n",
    "\n",
    "for lesson in pmd.lessons_learned:\n",
    "    print(f\"{lesson.lesson_label}: {lesson.explanation_and_justification}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5012ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50 movies in parallel...\n",
      "[1/50] âœ“ raiders of the lost ark\n",
      "[2/50] âœ“ john wick\n",
      "[3/50] âœ“ school of rock\n",
      "[4/50] âœ“ up\n",
      "[5/50] âœ“ coco\n",
      "[6/50] âœ“ the lord of the rings: the fellowship of the ring\n",
      "[7/50] âœ“ zootopia\n",
      "[8/50] âœ“ the year without a santa claus\n",
      "[9/50] âœ“ gladiator\n",
      "[10/50] âœ“ klaus\n",
      "[11/50] âœ“ the princess bride\n",
      "[12/50] âœ“ captain america: the first avenger\n",
      "[13/50] âœ“ mad max: fury road\n",
      "[14/50] âœ“ ferris bueller's day off\n",
      "[15/50] âœ“ frozen\n",
      "[16/50] âœ“ avengers: endgame\n",
      "[17/50] âœ“ the dark knight\n",
      "[18/50] âœ“ star wars\n",
      "[19/50] âœ“ interstellar\n",
      "[20/50] âœ“ the matrix\n",
      "[21/50] âœ“ shrek\n",
      "[22/50] âœ“ mulan\n",
      "[23/50] âœ“ spider-man: across the spider-verse\n",
      "[24/50] âœ“ harry potter and the philosopher's stone\n",
      "[25/50] âœ“ inception\n",
      "[26/50] âœ“ jurassic park\n",
      "[27/50] âœ“ blade runner 2049\n",
      "[28/50] âœ“ the shining\n",
      "[29/50] âœ“ terrifier 3\n",
      "[30/50] âœ“ hereditary\n",
      "[31/50] âœ“ past lives\n",
      "[32/50] âœ“ arrival\n",
      "[33/50] âœ“ american psycho\n",
      "[34/50] âœ“ saw\n",
      "[35/50] âœ“ fight club\n",
      "[36/50] âœ“ 50 first dates\n",
      "[37/50] âœ“ insidious\n",
      "[38/50] âœ“ fifty shades of grey\n",
      "[39/50] âœ“ titanic\n",
      "[40/50] âœ“ the notebook\n",
      "[41/50] âœ“ get out\n",
      "[42/50] âœ“ the pianist\n",
      "[43/50] âœ“ parasite\n",
      "[44/50] âœ“ leap year\n",
      "[45/50] âœ“ forrest gump\n",
      "[46/50] âœ“ se7en\n",
      "[47/50] âœ“ everything everywhere all at once\n",
      "[48/50] âœ“ scott pilgrim vs. the world\n",
      "[49/50] âœ“ murder on the orient express\n",
      "[50/50] âœ“ the naked gun: from the files of police squad!\n",
      "\n",
      "Completed processing 50 movies\n",
      "Successfully updated: 50\n",
      "Failed: 0\n",
      "\n",
      "âœ“ Saved 50 movies to ../../saved_imdb_movies.json\n"
     ]
    }
   ],
   "source": [
    "# PLOT METADATA REGENERATION\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "def process_single_movie_plot(args: Tuple[int, IMDBMovie]) -> Tuple[int, IMDBMovie, bool, str]:\n",
    "    \"\"\"\n",
    "    Process a single movie to generate plot metadata.\n",
    "    \n",
    "    Args:\n",
    "        args: Tuple of (index, movie) where index is the movie's position in the original list\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (index, updated_movie, success, error_message)\n",
    "        - index: Original position in the list (for maintaining order)\n",
    "        - updated_movie: Updated IMDBMovie object (or original if generation failed)\n",
    "        - success: Boolean indicating if generation was successful\n",
    "        - error_message: Error message if generation failed, empty string otherwise\n",
    "    \"\"\"\n",
    "    i, movie = args\n",
    "    \n",
    "    try:\n",
    "        plot_events_metadata = generate_plot_events_metadata(\n",
    "            title=movie.title,\n",
    "            overview=movie.overview,\n",
    "            plot_keywords=movie.plot_keywords,\n",
    "            plot_summaries=movie.debug_plot_summaries,\n",
    "            plot_synopses=movie.debug_synopses\n",
    "        )\n",
    "\n",
    "        if not plot_events_metadata:\n",
    "            raise Exception(\"Plot events metadata returned None\")\n",
    "\n",
    "        plot_analysis_metadata = generate_plot_analysis_metadata(\n",
    "            title=movie.title,\n",
    "            overview=movie.overview,\n",
    "            plot_synopsis=plot_events_metadata.plot_summary,\n",
    "            plot_keywords=movie.plot_keywords,\n",
    "            featured_reviews=movie.featured_reviews\n",
    "        )\n",
    "\n",
    "        if not plot_analysis_metadata:\n",
    "            raise Exception(\"Plot analysis metadata returned None\")\n",
    "\n",
    "        updated_movie = movie.model_copy(update={\n",
    "            \"plot_events_metadata\": plot_events_metadata,\n",
    "            \"plot_analysis_metadata\": plot_analysis_metadata\n",
    "        })\n",
    "        \n",
    "        return (i, updated_movie, True, \"\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Error occurred, keep original movie\n",
    "        return (i, movie, False, str(e))\n",
    "\n",
    "# Load movies from JSON file (relative to notebook location)\n",
    "json_path = Path(\"../../saved_imdb_movies.json\")\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    movies_data = json.load(f)\n",
    "\n",
    "# Convert each dictionary to an IMDBMovie object\n",
    "movies = [IMDBMovie(**movie_dict) for movie_dict in movies_data]\n",
    "\n",
    "# Process all movies in parallel using ThreadPoolExecutor\n",
    "# Using max_workers=10 for I/O-bound tasks like API calls\n",
    "print(f\"Processing {len(movies)} movies in parallel...\")\n",
    "updated_movies_dict = {}  # Use dict to maintain order by index\n",
    "failed_movies = []\n",
    "\n",
    "# Create list of (index, movie) tuples for processing\n",
    "movie_args = [(i, movie) for i, movie in enumerate(movies)]\n",
    "\n",
    "# Process movies in parallel\n",
    "with ThreadPoolExecutor(max_workers=25) as executor:\n",
    "    # Submit all tasks\n",
    "    future_to_movie = {executor.submit(process_single_movie_plot, args): args[1] for args in movie_args}\n",
    "    \n",
    "    # Process completed tasks as they finish\n",
    "    completed = 0\n",
    "    for future in as_completed(future_to_movie):\n",
    "        movie = future_to_movie[future]\n",
    "        completed += 1\n",
    "        \n",
    "        try:\n",
    "            index, updated_movie, success, error_msg = future.result()\n",
    "            updated_movies_dict[index] = updated_movie\n",
    "            \n",
    "            if success:\n",
    "                print(f\"[{completed}/{len(movies)}] âœ“ {movie.title}\")\n",
    "            else:\n",
    "                print(f\"[{completed}/{len(movies)}] âœ— {movie.title} - {error_msg}\")\n",
    "                failed_movies.append((index, movie.title, error_msg))\n",
    "        except Exception as e:\n",
    "            # Handle unexpected errors in result retrieval\n",
    "            print(f\"[{completed}/{len(movies)}] âœ— {movie.title} - Unexpected error: {str(e)}\")\n",
    "            # Find the index for this movie\n",
    "            for idx, m in enumerate(movies):\n",
    "                if m == movie:\n",
    "                    updated_movies_dict[idx] = movie\n",
    "                    failed_movies.append((idx, movie.title, f\"Unexpected error: {str(e)}\"))\n",
    "                    break\n",
    "\n",
    "# Reconstruct movies list in original order\n",
    "updated_movies = [updated_movies_dict[i] for i in range(len(movies))]\n",
    "\n",
    "print(f\"\\nCompleted processing {len(movies)} movies\")\n",
    "print(f\"Successfully updated: {len(updated_movies) - len(failed_movies)}\")\n",
    "print(f\"Failed: {len(failed_movies)}\")\n",
    "\n",
    "if failed_movies:\n",
    "    print(\"\\nFailed movies:\")\n",
    "    for idx, title, reason in failed_movies:\n",
    "        print(f\"  {idx}: {title} - {reason}\")\n",
    "\n",
    "# Save updated movies back to JSON file\n",
    "# Convert IMDBMovie objects to dictionaries for JSON serialization\n",
    "movies_data_updated = [movie.model_dump() for movie in updated_movies]\n",
    "\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(movies_data_updated, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nâœ“ Saved {len(updated_movies)} movies to {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6090c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jurassic park\n",
      "An industrialist opens a theme park of resurrected animals; when scientific hubris causes containment failureâ€”via sabotage and unforeseen biologyâ€”invited experts and children must survive cascading system failures and escape the island, exposing the costs of that scientific hubris.\n",
      "Scientific hubris causes containment failure\n",
      "Science fiction thriller, Creature feature\n",
      "large scale conflict\n",
      "linear narrative\n",
      "humbling, protective bonding\n",
      "cautionary tale\n",
      "Scientific hubris and consequences, Human vulnerability to nature\n",
      "Unchecked innovation has costs, Control is fragile','Respect natural limits\n",
      "dinosaur adventure, jungle adventure, action, adventure, sci-fi, thriller\n",
      "\n",
      "interstellar\n",
      "As Earth becomes uninhabitable, a former pilot leads an exploratory mission through a wormhole to find a new home, and the mission's exploration and sacrifices drive both a species-level survival effort and a personal struggle where time dilation and betrayal complicate attempts to save humanity; a final sacrifice yields crucial data transmitted through time that enables humanity's exodus and reconciles a fractured parent-child relationship.\n",
      "Humanity's survival via exploration\n",
      "Hard science fiction, Space exploration drama, Family drama\n",
      "global conflict\n",
      "linear narrative\n",
      "sacrifice for survival, parent-child reconciliation\n",
      "quest for survival\n",
      "Survival requiring sacrifice, Love transcending time\n",
      "Sacrifice can save a species, Love can defy time\n",
      "adventure epic, epic, psychological drama, quest, sci-fi epic, space sci-fi, time travel, adventure\n",
      "\n",
      "avengers: endgame\n",
      "After a cosmic mass-erasure devastates the world, a fractured ensemble of heroes reunites and executes a time heist to reverse the erasure and restore the vanished; the time heist succeeds but exacts tragic personal sacrifices, culminating in a final battle that resolves leadership and legacy.\n",
      "Time heist to reverse erasure\n",
      "Superhero epic, Ensemble action\n",
      "global conflict\n",
      "ensemble narrative\n",
      "redemption, passing the mantle\n",
      "saga finale\n",
      "Sacrifice for greater good, Legacy and passing responsibility\n",
      "Victory costs sacrifice, Legacy outlives individuals\n",
      "action epic, adventure epic, dark comedy, epic, sci-fi epic, space sci-fi, superhero, time travel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUGGING BAD MATCHES\n",
    "\n",
    "# List of title snippets to search for (case-insensitive)\n",
    "title_snippets = [\"jurass\", \"interstellar\", \"avengers: endga\"]\n",
    "\n",
    "# For each snippet, find matching movies and display their content vectors\n",
    "for snippet in title_snippets:\n",
    "    # Find movies whose titles contain the snippet (case-insensitive)\n",
    "    matching_movies = [\n",
    "        movie for movie in movies \n",
    "        if snippet.lower() in movie.title.lower()\n",
    "    ]\n",
    "    \n",
    "    if not matching_movies:\n",
    "        print(f\"No movies found matching '{snippet}'\")\n",
    "        print()\n",
    "        continue\n",
    "    \n",
    "    # If multiple matches, print all of them\n",
    "    if len(matching_movies) > 1:\n",
    "        print(f\"Found {len(matching_movies)} movies matching '{snippet}':\")\n",
    "        print()\n",
    "    \n",
    "    # Print each matching movie's title and content vector\n",
    "    for movie in matching_movies:\n",
    "        print(movie.title)\n",
    "        print(create_plot_analysis_vector_text(movie))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
